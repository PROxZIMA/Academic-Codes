{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6634fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "from nltk import WordNetLemmatizer, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c439a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "with open('News_dataset.pickle', 'rb') as f:\n",
    "    news = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4118e83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category</th>\n",
       "      <th>Complete_Filename</th>\n",
       "      <th>id</th>\n",
       "      <th>News_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...</td>\n",
       "      <td>business</td>\n",
       "      <td>001.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...</td>\n",
       "      <td>business</td>\n",
       "      <td>002.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...</td>\n",
       "      <td>business</td>\n",
       "      <td>003.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits\\r\\n\\r\\nBriti...</td>\n",
       "      <td>business</td>\n",
       "      <td>004.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...</td>\n",
       "      <td>business</td>\n",
       "      <td>005.txt-business</td>\n",
       "      <td>1</td>\n",
       "      <td>1575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>397.txt</td>\n",
       "      <td>BT program to beat dialler scams\\r\\n\\r\\nBT is ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>397.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>398.txt</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...</td>\n",
       "      <td>tech</td>\n",
       "      <td>398.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>399.txt</td>\n",
       "      <td>Be careful how you code\\r\\n\\r\\nA new European ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>399.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>6297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>400.txt</td>\n",
       "      <td>US cyber security chief resigns\\r\\n\\r\\nThe man...</td>\n",
       "      <td>tech</td>\n",
       "      <td>400.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>401.txt</td>\n",
       "      <td>Losing yourself in online gaming\\r\\n\\r\\nOnline...</td>\n",
       "      <td>tech</td>\n",
       "      <td>401.txt-tech</td>\n",
       "      <td>1</td>\n",
       "      <td>16248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_Name                                            Content  Category  \\\n",
       "0      001.txt  Ad sales boost Time Warner profit\\r\\n\\r\\nQuart...  business   \n",
       "1      002.txt  Dollar gains on Greenspan speech\\r\\n\\r\\nThe do...  business   \n",
       "2      003.txt  Yukos unit buyer faces loan claim\\r\\n\\r\\nThe o...  business   \n",
       "3      004.txt  High fuel prices hit BA's profits\\r\\n\\r\\nBriti...  business   \n",
       "4      005.txt  Pernod takeover talk lifts Domecq\\r\\n\\r\\nShare...  business   \n",
       "...        ...                                                ...       ...   \n",
       "2220   397.txt  BT program to beat dialler scams\\r\\n\\r\\nBT is ...      tech   \n",
       "2221   398.txt  Spam e-mails tempt net shoppers\\r\\n\\r\\nCompute...      tech   \n",
       "2222   399.txt  Be careful how you code\\r\\n\\r\\nA new European ...      tech   \n",
       "2223   400.txt  US cyber security chief resigns\\r\\n\\r\\nThe man...      tech   \n",
       "2224   401.txt  Losing yourself in online gaming\\r\\n\\r\\nOnline...      tech   \n",
       "\n",
       "     Complete_Filename  id  News_length  \n",
       "0     001.txt-business   1         2569  \n",
       "1     002.txt-business   1         2257  \n",
       "2     003.txt-business   1         1557  \n",
       "3     004.txt-business   1         2421  \n",
       "4     005.txt-business   1         1575  \n",
       "...                ...  ..          ...  \n",
       "2220      397.txt-tech   1         2526  \n",
       "2221      398.txt-tech   1         2294  \n",
       "2222      399.txt-tech   1         6297  \n",
       "2223      400.txt-tech   1         2323  \n",
       "2224      401.txt-tech   1        16248  \n",
       "\n",
       "[2225 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc85f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(news, columns=['Content', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6695be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Content   2225 non-null   object\n",
      " 1   Category  2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03456c73",
   "metadata": {},
   "source": [
    "### Text cleaning, Lemmatization and Stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc661aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# define a function for text cleaning, lemmatization and stop word removal\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
    "    text = text.lower() # convert to lowercase\n",
    "    tokens = word_tokenize(text) # tokenize the text\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # lemmatize the tokens\n",
    "    tokens = [token for token in tokens if token not in stop_words] # remove stop words\n",
    "    clean_text = ' '.join(tokens)\n",
    "    return clean_text\n",
    "\n",
    "# apply the function to the 'news' column\n",
    "df['clean_text'] = df['Content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25af69b",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae15c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the 'category' column\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f4093",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504f934f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27401</th>\n",
       "      <td>timewarner</td>\n",
       "      <td>0.487146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21674</th>\n",
       "      <td>profit</td>\n",
       "      <td>0.344867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>aol</td>\n",
       "      <td>0.257683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29256</th>\n",
       "      <td>warner</td>\n",
       "      <td>0.210784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23199</th>\n",
       "      <td>revenue</td>\n",
       "      <td>0.141471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word     Count\n",
       "27401  timewarner  0.487146\n",
       "21674      profit  0.344867\n",
       "3442          aol  0.257683\n",
       "29256      warner  0.210784\n",
       "23199     revenue  0.141471"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create TF-IDF representations of the clean text\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_count_occurs = tfidf_vec.fit_transform(df['clean_text'])\n",
    "tfidf_count_occur_df = pd.DataFrame((count, word) for word, count in zip(\n",
    "tfidf_count_occurs.toarray().tolist()[0], tfidf_vec.get_feature_names_out()))\n",
    "tfidf_count_occur_df.columns = ['Word', 'Count']\n",
    "tfidf_count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
    "tfidf_count_occur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2444b75b",
   "metadata": {},
   "source": [
    "### Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13aa9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed data and the TF-IDF vectorizer\n",
    "with open('processed_data.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "with open('tfidf.pickle', 'wb') as f:\n",
    "    pickle.dump(tfidf_vec, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
