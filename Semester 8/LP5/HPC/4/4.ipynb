{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hhiln58gDJhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6876d4c4-5908-4bba-c68c-8e9f355b98b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrixMul.cu\n",
        "#include <cmath>\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "// Matrix multiplication Cuda\n",
        "__global__ void matrixMultiplication(int *a, int *b, int *c, int n) {\n",
        "    int row = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "    int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    int sum = 0;\n",
        "\n",
        "    if (row < n && col < n)\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            sum = sum + a[row * n + j] * b[j * n + col];\n",
        "        }\n",
        "\n",
        "    c[n * row + col] = sum;\n",
        "}\n",
        "int main() {\n",
        "    int *a, *b, *c;\n",
        "    int *a_dev, *b_dev, *c_dev;\n",
        "    int n = 3;\n",
        "\n",
        "    a = new int[n * n];\n",
        "    b = new int[n * n];\n",
        "    c = new int[n * n];\n",
        "    int *d = new int[n * n];\n",
        "    int size = n * n * sizeof(int);\n",
        "    cudaMalloc(&a_dev, size);\n",
        "    cudaMalloc(&b_dev, size);\n",
        "    cudaMalloc(&c_dev, size);\n",
        "\n",
        "    // Array initialization\n",
        "    for (int i = 0; i < n * n; i++) {\n",
        "        a[i] = 2;  // rand()%n;\n",
        "        b[i] = 1;  // rand()%n;\n",
        "        // d[i]=a[i]+b[i];\n",
        "    }\n",
        "\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaMemcpy(a_dev, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(b_dev, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(n, n);\n",
        "    dim3 blocksPerGrid(1, 1);\n",
        "\n",
        "    if (n * n > 512) {\n",
        "        threadsPerBlock.x = 512;\n",
        "        threadsPerBlock.y = 512;\n",
        "        blocksPerGrid.x = ceil((double)n / (double)threadsPerBlock.x);\n",
        "        blocksPerGrid.y = ceil((double)n / (double)threadsPerBlock.y);\n",
        "    }\n",
        "    // GPU Multiplication\n",
        "    cudaEventRecord(start);\n",
        "    matrixMultiplication<<<blocksPerGrid, threadsPerBlock>>>(a_dev, b_dev, c_dev, n);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    float time = 0.0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "    cudaMemcpy(c, c_dev, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // CPU matrix multiplication\n",
        "    int sum = 0;\n",
        "    for (int row = 0; row < n; row++) {\n",
        "        for (int col = 0; col < n; col++) {\n",
        "            sum = 0;\n",
        "            for (int k = 0; k < n; k++) sum = sum + a[row * n + k] * b[k * n + col];\n",
        "            d[row * n + col] = sum;\n",
        "        }\n",
        "    }\n",
        "    int error = 0;\n",
        "    for (int i = 0; i < n * n; i++) {\n",
        "        error += d[i] - c[i];\n",
        "        // cout<<\" gpu \"<<c[i]<<\" CPU \"<<d[i]<<endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Error : \" << error;\n",
        "    cout << \"\\nTime Elapsed:  \" << time;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuifZuaFEcMg",
        "outputId": "417d90d2-d691-4051-cfea-a9eb15095020"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrixMul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrixVectorMul.cu\n",
        "#include <time.h>\n",
        "\n",
        "#include <cmath>\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matrixVectorMultiplication(int *a, int *b, int *c, int n) {\n",
        "    int row = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "    int sum = 0;\n",
        "\n",
        "    if (row < n)\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            sum = sum + a[row * n + j] * b[j];\n",
        "        }\n",
        "\n",
        "    c[row] = sum;\n",
        "}\n",
        "int main() {\n",
        "    int *a, *b, *c;\n",
        "    int *a_dev, *b_dev, *c_dev;\n",
        "    int n = 32;\n",
        "\n",
        "    a = new int[n * n];\n",
        "    b = new int[n];\n",
        "    c = new int[n];\n",
        "    int *d = new int[n];\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&a_dev, size * size);\n",
        "    cudaMalloc(&b_dev, size);\n",
        "    cudaMalloc(&c_dev, size);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            a[i * n + j] = i * n + j + 1;  // rand()%n;\n",
        "        }\n",
        "\n",
        "        b[i] = i + 1;  // rand()%n;\n",
        "        // cout<<a[i]<<\" \";\n",
        "        // d[i]=a[i]+b[i];\n",
        "    }\n",
        "\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaMemcpy(a_dev, a, size * size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(b_dev, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(n, n);\n",
        "    dim3 blocksPerGrid(1, 1);\n",
        "\n",
        "    if (n * n > 512) {\n",
        "        threadsPerBlock.x = 512;\n",
        "        threadsPerBlock.y = 512;\n",
        "        blocksPerGrid.x = ceil((double)n / (double)threadsPerBlock.x);\n",
        "        blocksPerGrid.y = ceil((double)n / (double)threadsPerBlock.y);\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "    matrixVectorMultiplication<<<blocksPerGrid, threadsPerBlock>>>(a_dev, b_dev, c_dev, n);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    float time = 0.0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "    cudaMemcpy(c, c_dev, size, cudaMemcpyDeviceToHost);\n",
        "    cout << \"\\nGPU Time Elapsed:  \" << time;\n",
        "\n",
        "    // CPU matrixVector multiplication\n",
        "    clock_t t = clock();\n",
        "    int sum = 0;\n",
        "    for (int row = 0; row < n; row++) {\n",
        "        sum = 0;\n",
        "        for (int col = 0; col < n; col++) {\n",
        "            sum = sum + a[row * n + col] * b[col];\n",
        "        }\n",
        "        d[row] = sum;\n",
        "    }\n",
        "    t = clock() - t;\n",
        "    cout << \"\\nCPU Time Elapsed:  \" << ((double)t);  //((double)t)/CLOCKS_PER_SEC;\n",
        "\n",
        "    int error = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        error += d[i] - c[i];\n",
        "        // cout<<\" gpu \"<<c[i]<<\" CPU \"<<d[i]<<endl;\n",
        "    }\n",
        "\n",
        "    cout << \"Error : \" << error;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg2OV22DYWut",
        "outputId": "689f91cd-6e3e-45fa-b674-ab6fa0c0015f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrixVectorMul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vectorAdd.cu\n",
        "#include <cstdlib>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "// VectorAdd parallel function\n",
        "__global__ void vectorAdd(int *a, int *b, int *result, int n) {\n",
        "    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (tid < n) {\n",
        "        result[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "int main() {\n",
        "    int *a, *b, *c;\n",
        "    int *a_dev, *b_dev, *c_dev;\n",
        "    int n = 1 << 24;\n",
        "\n",
        "    a = new int[n];\n",
        "    b = new int[n];\n",
        "    c = new int[n];\n",
        "    int *d = new int[n];\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&a_dev, size);\n",
        "    cudaMalloc(&b_dev, size);\n",
        "    cudaMalloc(&c_dev, size);\n",
        "\n",
        "    // Array initialization..You can use Randon function to assign values\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = 1;\n",
        "        b[i] = 2;\n",
        "        d[i] = a[i] + b[i];  // calculating serial addition\n",
        "    }\n",
        "\n",
        "    cudaEvent_t start, end;\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "\n",
        "    cudaMemcpy(a_dev, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(b_dev, b, size, cudaMemcpyHostToDevice);\n",
        "    int threads = 1024;\n",
        "    int blocks = (n + threads - 1) / threads;\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Parallel addition program\n",
        "    vectorAdd<<<blocks, threads>>>(a_dev, b_dev, c_dev, n);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    float time = 0.0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "    cudaMemcpy(c, c_dev, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Calculate the error term.\n",
        "    int error = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        error += d[i] - c[i];\n",
        "        // cout<<\" gpu \"<<c[i]<<\" CPU \"<<d[i];\n",
        "    }\n",
        "\n",
        "    cout << \"Error : \" << error;\n",
        "    cout << \"\\nTime Elapsed:  \" << time;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY8YBqwRcKjv",
        "outputId": "ebbcbfd7-9fc5-4654-d27d-8ec0203f3e90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vectorAdd.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -dc matrixMul.cu\n",
        "!nvcc *.o -o ./matrixMul && ./matrixMul\n",
        "!rm -rf *.o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKbz6lcAEkr3",
        "outputId": "717a274c-9342-4334-cc6d-0fd35bdb4f56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error : 0\n",
            "Time Elapsed:  0.022528"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -dc matrixVectorMul.cu\n",
        "!nvcc *.o -o ./matrixVectorMul && ./matrixVectorMul\n",
        "!rm -rf *.o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTNlaV27Ylkh",
        "outputId": "7867c62d-3c1e-4b8e-d6ff-2a7517fe0fcc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPU Time Elapsed:  0.005536\n",
            "CPU Time Elapsed:  5Error : 8746496"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -dc vectorAdd.cu\n",
        "!nvcc *.o -o ./vectorAdd && ./vectorAdd\n",
        "!rm -rf *.o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KwNJ7U-c3l6",
        "outputId": "70866662-3d48-45b4-8f11-de38315cf751"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error : 0\n",
            "Time Elapsed:  0.798464"
          ]
        }
      ]
    }
  ]
}